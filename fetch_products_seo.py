import os
import sys
import time
import hmac
import hashlib
import base64
import requests
import random
import pathlib
import urllib.parse

# === í—¬í¼: ì¸ì½”ë”© ===
def _enc_rfc3986(v: str) -> str:
    # ê³µë°± â†’ %20, ì•ˆì „ë¬¸ìë§Œ í—ˆìš©(RFC3986)
    return urllib.parse.quote(str(v), safe="-_.~")

def _build_query(params, space_plus=False) -> str:
    # space_plus=True â†’ urllib í‘œì¤€(+)
    # space_plus=False â†’ RFC3986(%20)
    if space_plus:
        return urllib.parse.urlencode(params, doseq=True)
    return "&".join(f"{_enc_rfc3986(k)}={_enc_rfc3986(v)}" for k, v in params)
    
# 1) í™˜ê²½ë³€ìˆ˜(ì‹œí¬ë¦¿) ë¨¼ì € ë¡œë“œ
ACCESS_KEY = os.getenv("ACCESS_KEY")
SECRET_KEY = os.getenv("SECRET_KEY")

# 2) ë§ˆìŠ¤í‚¹ í•¨ìˆ˜ + í‚¤ ì¡´ì¬/ê¸¸ì´ ë¡œê·¸
def _mask(v):
    return "(none)" if not v else f"len={len(v)} head={v[:3]}***"

print("ACCESS_KEY_PRESENT=", "YES" if ACCESS_KEY else "NO", _mask(ACCESS_KEY))
print("SECRET_KEY_PRESENT=", "YES" if SECRET_KEY else "NO", _mask(SECRET_KEY))
# ===== [ë””ë²„ê·¸: ì‹¤í–‰ í™˜ê²½ ì¶œë ¥] =====
print("== DEBUG START ==")
print("PYTHON_VERSION=", sys.version)
print("CWD=", os.getcwd())
print("FILES=", [p.name for p in pathlib.Path(".").glob("*")])
print("HAS_INDEX=", os.path.exists("index.html"))
print("DEBUG_LOG=", os.getenv("DEBUG_LOG", ""))
print("COUNT_ENV=", os.getenv("COUNT", ""))

# ===== [í™˜ê²½ë³€ìˆ˜/ìƒìˆ˜] =====
ACCESS_KEY = os.getenv("ACCESS_KEY")
SECRET_KEY = os.getenv("SECRET_KEY")
COUNT = int(os.getenv("COUNT", "30"))  # í•˜ë£¨ì— ëª‡ ê°œ ë¿Œë¦´ì§€ ì»¨íŠ¸ë¡¤
DEBUG = os.getenv("DEBUG_LOG") == "1"

DOMAIN = "https://api-gateway.coupang.com"

# ëŒ€í‘œ ì‚¬ì´íŠ¸ ì£¼ì†Œ(ì •í™•í•œ ë„ë©”ì¸ + ëì— / ê¶Œì¥)
SITE_URL = "https://rkskqdl-a11y.github.io/yourshop/"

SEARCH_KEYWORDS = [
    "ë…¸íŠ¸ë¶", "ê²Œì´ë° ëª¨ë‹ˆí„°", "ë¬´ì„  ì´ì–´í°", "ìŠ¤ë§ˆíŠ¸ì›Œì¹˜", "ì²­ì†Œê¸°",
    "ì•ˆë§ˆì˜ì", "ì»¤í”¼ë¨¸ì‹ ", "ì—ì–´í”„ë¼ì´ì–´", "ê²Œì´ë° í‚¤ë³´ë“œ", "ë§ˆìš°ìŠ¤",
    "ì•„ì´í° ì¼€ì´ìŠ¤", "ê°¤ëŸ­ì‹œ ì¶©ì „ê¸°", "ìŠ¤íƒ ë“œ ì¡°ëª…", "ê³µê¸°ì²­ì •ê¸°", "ì „ë™ í‚¥ë³´ë“œ",
    "ìì „ê±°", "í—¬ìŠ¤ ë³´ì¶©ì œ", "ìº í•‘ ìš©í’ˆ", "ì—¬í–‰ ê°€ë°©", "íŒ¨ì…˜ ì‹ ë°œ", "ì•„ë™ ì¥ë‚œê°"
]

# ì´ë¯¸ ë§¨ ìœ„ì— ìˆìŒ: import urllib.parse, import requests, import time, hmac, hashlib, base64

def generate_hmac(method: str, path_with_query: str, secret_key: str, access_key: str, dt: str) -> str:
    """
    dt: ë‚ ì§œ ë¬¸ìì—´(ì´ë¯¸ ë§Œë“¤ì–´ì§„ ê°’ ì‚¬ìš©)
    path_with_query: '/.../path?key=val&...' ìµœì¢… ë¬¸ìì—´(ì¿¼ë¦¬ í¬í•¨)
    """
    path, query = (path_with_query.split("?", 1) + [""])[:2]
    message = dt + method + path + query
    signature = hmac.new(secret_key.encode("utf-8"), message.encode("utf-8"), hashlib.sha256).digest()
    signed = base64.b64encode(signature).decode("utf-8")
    return f"CEA algorithm=HmacSHA256, access-key={access_key}, signed-date={dt}, signature={signed}"

# === ìƒí’ˆ ì¡°íšŒ(ë©€í‹° í¬ë§· ìë™ ì‹œë„) ===
def fetch_products(keyword: str):
    path = "/v2/providers/affiliate_open_api/apis/openapi/v1/products/search"
    params = [("keyword", keyword), ("limit", 50)]

    # ì‹œë„í•  ì¡°í•©(ìƒëŒ€ê°€ ë­˜ ê¸°ëŒ€í•˜ë“  ìë™ìœ¼ë¡œ ë§ì¶”ê¸°)
    # 1) ISO8601 + RFC3986(%20)
    # 2) yyyymmddTHHMMSSZ + RFC3986(%20)
    # 3) yyyymmddTHHMMSSZ + urlencoded(+)
    attempts = [
        (lambda: time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()), False),
        (lambda: time.strftime("%Y%m%dT%H%M%SZ", time.gmtime()), False),
        (lambda: time.strftime("%Y%m%dT%H%M%SZ", time.gmtime()), True),
    ]

    last_err = None
    for dt_func, space_plus in attempts:
        dt = dt_func()
        q = _build_query(params, space_plus=space_plus)
        path_with_query = f"{path}?{q}"
        url = f"{DOMAIN}{path_with_query}"

        auth = generate_hmac("GET", path_with_query, SECRET_KEY, ACCESS_KEY, dt)
        headers = {
            "Authorization": auth,
            "Content-Type": "application/json;charset=UTF-8",
            "X-Authorization-Date": dt,  # ì°¸ê³ ìš©
        }

        resp = requests.get(url, headers=headers, timeout=10)

        if 'DEBUG' in globals() and DEBUG:
            enc_mode = "plus" if space_plus else "rfc3986"
            print(f"[TRY] dt={dt} enc={enc_mode} url={resp.request.url} status={resp.status_code} len={len(resp.content)}")
            if resp.status_code >= 400:
                print("[BODY]", (resp.text or "")[:300])
            else:
                print("[OK] matched: dt=", dt, " enc=", enc_mode)

        if resp.status_code == 200:
            try:
                data = resp.json()
            except Exception as e:
                last_err = e
                break
            return data.get("data", {}).get("productData", []) or []
        else:
            last_err = resp.text

    print(f"[WARN] all signature attempts failed. last_err={str(last_err)[:200]}")
    return []

def fetch_random_products():
    all_products = []
    for kw in SEARCH_KEYWORDS:
        all_products.extend(fetch_products(kw))
    random.shuffle(all_products)
    # COUNT ê°œìˆ˜ë§Œí¼ ìë¥´ê¸°
    picked = all_products[:COUNT] if all_products else []
    return picked

def build_html(products):
    seo_title = "ì˜¤ëŠ˜ì˜ ì¶”ì²œ íŠ¹ê°€ìƒí’ˆ 30ì„  | ì‡¼í•‘ëª° ë² ìŠ¤íŠ¸"
    seo_description = "ê°€ì „ì œí’ˆ, íŒ¨ì…˜, ìº í•‘ìš©í’ˆ, í—¬ìŠ¤, ì•„ë™ ì¥ë‚œê°ê¹Œì§€ ì˜¤ëŠ˜ì˜ ì¶”ì²œ ë² ìŠ¤íŠ¸ íŠ¹ê°€ìƒí’ˆ 30ê°œë¥¼ ëª¨ì•˜ìŠµë‹ˆë‹¤."
    seo_keywords = ",".join(SEARCH_KEYWORDS)
    og_image = (products[0].get("imageUrl") if products else "") or ""

    html = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>{seo_title}</title>
    <meta name="description" content="{seo_description}">
    <meta name="keywords" content="{seo_keywords}">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Open Graph -->
    <meta property="og:title" content="{seo_title}">
    <meta property="og:description" content="{seo_description}">
    <meta property="og:image" content="{og_image}">
    <meta property="og:url" content="{SITE_URL}">
    <link rel="canonical" href="{SITE_URL}">
    <meta name="twitter:card" content="summary_large_image">

    <style>
        body {{ font-family: Arial, sans-serif; max-width: 1200px; margin: auto; padding: 20px; }}
        .grid {{ display: grid; grid-template-columns: repeat(auto-fill, minmax(250px, 1fr)); gap: 20px; }}
        article {{ border: 1px solid #ddd; padding: 10px; border-radius: 10px; box-shadow: 2px 2px 8px rgba(0,0,0,0.1); }}
        article img {{ max-width: 100%; border-radius: 10px; }}
        .price {{ font-weight: bold; color: red; margin-top: 5px; }}
        .btn {{ display: inline-block; margin-top: 10px; padding: 8px 12px; background: #ff5722; color: #fff; text-decoration: none; border-radius: 5px; }}
        .btn:hover {{ background: #e64a19; }}
    </style>
</head>
<body>
    <h1>{seo_title}</h1>
    <p>â€» ì´ í¬ìŠ¤íŒ…ì€ ì¿ íŒ¡ íŒŒíŠ¸ë„ˆìŠ¤ í™œë™ì˜ ì¼í™˜ìœ¼ë¡œ, ì¼ì •ì•¡ì˜ ìˆ˜ìˆ˜ë£Œë¥¼ ì œê³µë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
    <div class="grid">
"""
    for p in products:
        name = (p.get("productName") or "")[:60]
        desc = (p.get("productName") or "")[:120]
        price = p.get("price") or ""
        img = p.get("imageUrl") or ""
        link = p.get("productUrl") or "#"
        html += f"""
        <article itemscope itemtype="https://schema.org/Product">
            <h2 itemprop="name">{name}...</h2>
            <img src="{img}" alt="{name}" itemprop="image">
            <p class="price"><span itemprop="price">{price}</span>ì›</p>
            <a class="btn" href="{link}" target="_blank" rel="nofollow noopener" itemprop="url">ğŸ‘‰ ë³´ëŸ¬ê°€ê¸°</a>
            <meta itemprop="brand" content="ì¿ íŒ¡">
            <meta itemprop="description" content="{desc}">
        </article>
"""
    html += """
    </div>
</body>
</html>
"""
    return html

def build_sitemap(products):
    # ì£¼ì˜: ì¿ íŒ¡ ì™¸ë¶€ URLì€ ë„¤ ë„ë©”ì¸ì´ ì•„ë‹ˆë¯€ë¡œ sitemapì—ëŠ” ë„£ì§€ ì•ŠëŠ” ê²Œ ì •ì„
    # ë„¤ ì‚¬ì´íŠ¸ ëŒ€í‘œ URLë§Œ ë„£ì.
    urls = [SITE_URL]
    xml = '<?xml version="1.0" encoding="UTF-8"?>\n'
    xml += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
    for url in urls:
        xml += f"  <url><loc>{url}</loc></url>\n"
    xml += "</urlset>"
    return xml

def build_robots():
    return f"""User-agent: *
Allow: /
Sitemap: {SITE_URL}sitemap.xml
"""

if __name__ == "__main__":
    # ë°ì´í„° ìˆ˜ì§‘
    products = fetch_random_products()

    # ìˆ˜ì§‘ ê²°ê³¼ ë¡œê·¸
    print(f"PRODUCT_COUNT={len(products)}")
    if products:
        try:
            print("FIRST_ITEM_TITLE=", str(products[0].get("productName", ""))[:80])
        except Exception as e:
            print("[WARN] first item preview failed:", e)

    # ë””ë²„ê·¸ ëª¨ë“œì—ì„œ ë¹„ì—ˆìœ¼ë©´ ë”ë¯¸ 1ê°œ ì£¼ì…(íŒŒì´í”„ë¼ì¸ ì ê²€)
    if not products and DEBUG:
        products = [{
            "productName": "ìƒ˜í”Œ ìƒí’ˆ(ì ê²€ìš©)",
            "price": "9,900",
            "imageUrl": "https://via.placeholder.com/600x400?text=Sample",
            "productUrl": "https://www.coupang.com/",
        }]
        print("[WARN] products empty â†’ injected 1 dummy item for pipeline test.")

    # íŒŒì¼ ìƒì„±
    html = build_html(products)
    sitemap = build_sitemap(products)
    robots = build_robots()

    # ì €ì¥
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(html)
    with open("sitemap.xml", "w", encoding="utf-8") as f:
        f.write(sitemap)
    with open("robots.txt", "w", encoding="utf-8") as f:
        f.write(robots)

    print("[OK] index.html/sitemap.xml/robots.txt written")
    print("== DEBUG END ==")
