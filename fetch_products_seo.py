import os
import sys
import time
import hmac
import hashlib
import base64
import requests
import random
import pathlib
import urllib.parse

# === í—¬í¼: ì¸ì½”ë”© ===
def _enc_rfc3986(v: str) -> str:
    # ê³µë°± â†’ %20, ì•ˆì „ë¬¸ìë§Œ í—ˆìš©(RFC3986)
    return urllib.parse.quote(str(v), safe="-_.~")

def _build_query(params, space_plus=False) -> str:
    # space_plus=True â†’ urllib í‘œì¤€(+)
    # space_plus=False â†’ RFC3986(%20)
    if space_plus:
        return urllib.parse.urlencode(params, doseq=True)
    return "&".join(f"{_enc_rfc3986(k)}={_enc_rfc3986(v)}" for k, v in params)
    
# 1) í™˜ê²½ë³€ìˆ˜(ì‹œí¬ë¦¿) ë¨¼ì € ë¡œë“œ
ACCESS_KEY = os.getenv("ACCESS_KEY")
SECRET_KEY = os.getenv("SECRET_KEY")

# 2) ë§ˆìŠ¤í‚¹ í•¨ìˆ˜ + í‚¤ ì¡´ì¬/ê¸¸ì´ ë¡œê·¸
def _mask(v):
    return "(none)" if not v else f"len={len(v)} head={v[:3]}***"

print("ACCESS_KEY_PRESENT=", "YES" if ACCESS_KEY else "NO", _mask(ACCESS_KEY))
print("SECRET_KEY_PRESENT=", "YES" if SECRET_KEY else "NO", _mask(SECRET_KEY))
# ===== [ë””ë²„ê·¸: ì‹¤í–‰ í™˜ê²½ ì¶œë ¥] =====
print("== DEBUG START ==")
print("PYTHON_VERSION=", sys.version)
print("CWD=", os.getcwd())
print("FILES=", [p.name for p in pathlib.Path(".").glob("*")])
print("HAS_INDEX=", os.path.exists("index.html"))
print("DEBUG_LOG=", os.getenv("DEBUG_LOG", ""))
print("COUNT_ENV=", os.getenv("COUNT", ""))

# ===== [í™˜ê²½ë³€ìˆ˜/ìƒìˆ˜] =====
ACCESS_KEY = os.getenv("ACCESS_KEY")
SECRET_KEY = os.getenv("SECRET_KEY")
COUNT = int(os.getenv("COUNT", "30"))  # í•˜ë£¨ì— ëª‡ ê°œ ë¿Œë¦´ì§€ ì»¨íŠ¸ë¡¤
DEBUG = os.getenv("DEBUG_LOG") == "1"

DOMAIN = "https://api-gateway.coupang.com"

# ëŒ€í‘œ ì‚¬ì´íŠ¸ ì£¼ì†Œ(ì •í™•í•œ ë„ë©”ì¸ + ëì— / ê¶Œì¥)
SITE_URL = "https://rkskqdl-a11y.github.io/yourshop/"

SEARCH_KEYWORDS = [
    "ë…¸íŠ¸ë¶", "ê²Œì´ë° ëª¨ë‹ˆí„°", "ë¬´ì„  ì´ì–´í°", "ìŠ¤ë§ˆíŠ¸ì›Œì¹˜", "ì²­ì†Œê¸°",
    "ì•ˆë§ˆì˜ì", "ì»¤í”¼ë¨¸ì‹ ", "ì—ì–´í”„ë¼ì´ì–´", "ê²Œì´ë° í‚¤ë³´ë“œ", "ë§ˆìš°ìŠ¤",
    "ì•„ì´í° ì¼€ì´ìŠ¤", "ê°¤ëŸ­ì‹œ ì¶©ì „ê¸°", "ìŠ¤íƒ ë“œ ì¡°ëª…", "ê³µê¸°ì²­ì •ê¸°", "ì „ë™ í‚¥ë³´ë“œ",
    "ìì „ê±°", "í—¬ìŠ¤ ë³´ì¶©ì œ", "ìº í•‘ ìš©í’ˆ", "ì—¬í–‰ ê°€ë°©", "íŒ¨ì…˜ ì‹ ë°œ", "ì•„ë™ ì¥ë‚œê°"
]

# ì´ë¯¸ ë§¨ ìœ„ì— ìˆìŒ: import urllib.parse, import requests, import time, hmac, hashlib, base64

def generate_hmac(method: str, path_with_query: str, secret_key: str, access_key: str, dt: str | None = None) -> tuple[str, str]:
    """
    dt: yyMMddTHHmmssZ (ì˜ˆ: 250830T130123Z). Noneì´ë©´ í˜„ì¬ UTCë¡œ ìƒì„±.
    path_with_query: '/.../path?key=val&...' (ë„ë©”ì¸ ì œì™¸, ìµœì¢… ì¸ì½”ë”© ë¬¸ìì—´)
    return: (Authorization í—¤ë” ë¬¸ìì—´, dt)
    """
    if dt is None:
        dt = time.strftime('%y%m%d', time.gmtime()) + 'T' + time.strftime('%H%M%S', time.gmtime()) + 'Z'

    path, query = (path_with_query.split("?", 1) + [""])[:2]
    message = dt + method + path + query  # ë¬¸ì„œ: datetime + method + path + query

    # hexdigestë¡œ ì„œëª…(ë¬¸ì„œ ë°©ì‹)
    signature = hmac.new(secret_key.encode("utf-8"), message.encode("utf-8"), hashlib.sha256).hexdigest()

    auth = f"CEA algorithm=HmacSHA256, access-key={access_key}, signed-date={dt}, signature={signature}"
    return auth, dt

# === ìƒí’ˆ ì¡°íšŒ(ë©€í‹° í¬ë§·/ì„œëª…ì¿¼ë¦¬ ìë™ ì‹œë„ í™•ì¥íŒ) ===
def fetch_products(keyword: str):
    """
    1) PreparedRequestë¡œ ìµœì¢… URL ìƒì„±(ìš°ë¦¬ê°€ ì´ë¯¸ ì¸ì¦ì€ OK)
    2) hexdigest + yyMMddTHHmmssZ í¬ë§·ìœ¼ë¡œ ì„œëª…
    3) ì‘ë‹µ JSONì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì°¾ì•„ ì •ê·œí™”í•´ì„œ ë°˜í™˜
    """
    path = "/v2/providers/affiliate_open_api/apis/openapi/v1/products/search"
    params = {"keyword": keyword, "limit": 50}

    # ìµœì¢… URL
    req = requests.Request("GET", DOMAIN + path, params=params)
    prep = req.prepare()
    parsed = urllib.parse.urlsplit(prep.url)
    path_with_query = parsed.path + (("?" + parsed.query) if parsed.query else "")

    # ì¿ íŒ¡ ë¬¸ì„œ í¬ë§·(hexdigest + yyMMddTHHmmssZ)
    authorization, dt = generate_hmac("GET", path_with_query, SECRET_KEY, ACCESS_KEY, None)
    prep.headers["Authorization"] = authorization
    prep.headers["Content-Type"] = "application/json;charset=UTF-8"

    s = requests.Session()
    resp = s.send(prep, timeout=10)

    if DEBUG:
        print(f"[REQ] url={resp.request.url} status={resp.status_code} len={len(resp.content)}")
        if resp.status_code >= 400:
            print("[BODY]", (resp.text or "")[:800])

    try:
        resp.raise_for_status()
        txt = resp.text or ""
        if DEBUG: print("[BODYFULL]", txt[:2000])
        j = resp.json()
    except Exception as e:
        print("[WARN] json parse fail:", e)
        return []

    # 1) data ë…¸ë“œ ë¶„ë¦¬(ì—†ìœ¼ë©´ ë¹ˆ dict)
    d = j.get("data") if isinstance(j, dict) else {}
    if d is None:
        d = {}

    # 2) ì œí’ˆ ë¦¬ìŠ¤íŠ¸ê°€ ìˆì„ ë²•í•œ ê²½ë¡œë“¤ì„ ì°¨ë¡€ë¡œ ê²€ì‚¬
    candidates = None
    candidate_paths = [
        ("productData",),           # ë¬¸ì„œ ì˜ˆì‹œ
        ("products",),              # ë³€í˜• ì¼€ì´ìŠ¤
        ("content",),               # ê°„í˜¹ ì»¨í…ì¸  ë°°ì—´ë¡œ ì˜¬ ë•Œ
        ("productList",),           # ë‹¤ë¥¸ ì‘ë‹µêµ°
        (),                         # data ìì²´ê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
    ]

    for path_tuple in candidate_paths:
        node = d
        if path_tuple:  # dict ì•ˆì„ ë‚´ë ¤ê°
            for k in path_tuple:
                if isinstance(node, dict):
                    node = node.get(k)
                else:
                    node = None
                    break
        # ë¹ˆ íŠœí”Œì´ë©´ data ìì²´ ê²€ì‚¬
        else:
            node = d

        if isinstance(node, list) and len(node) > 0:
            candidates = node
            break

    # 3) í˜¹ì‹œ data ë°”ê¹¥ ìµœìƒìœ„ì— ë¦¬ìŠ¤íŠ¸ê°€ ì˜¤ëŠ” ì¼€ì´ìŠ¤
    if not candidates and isinstance(j, dict):
        for k in ("productData", "products", "content", "productList"):
            node = j.get(k)
            if isinstance(node, list) and len(node) > 0:
                candidates = node
                break

    if not candidates:
        # ë””ë²„ê·¸ìš©ìœ¼ë¡œ í‚¤ ë³´ì—¬ì£¼ê¸°
        if DEBUG and isinstance(d, dict):
            print("[INFO] data keys:", list(d.keys()))
        return []

    # 4) í•„ë“œëª… ì •ê·œí™”(í…œí”Œë¦¿ì—ì„œ ì“°ëŠ” í‚¤ë¡œ ë³€í™˜)
    def norm(p: dict) -> dict:
        title = p.get("productName") or p.get("title") or ""
        price = p.get("productPrice") or p.get("price") or p.get("lowestPrice") or ""
        img   = p.get("imageUrl") or p.get("image") or ""
        link  = p.get("productUrl") or p.get("link") or ""
        return {
            "productName": title,
            "productPrice": price,
            "imageUrl": img,
            "productUrl": link
        }

    items = [norm(x) for x in candidates if isinstance(x, dict)]

    if DEBUG:
        print("PARSED_COUNT=", len(items))
        if items:
            print("FIRST_ITEM_SAMPLE=", {k: items[0].get(k) for k in ("productName", "productPrice", "imageUrl", "productUrl")})

    return items
def fetch_random_products():
    all_products = []
    for kw in SEARCH_KEYWORDS:
        all_products.extend(fetch_products(kw))
    random.shuffle(all_products)
    # COUNT ê°œìˆ˜ë§Œí¼ ìë¥´ê¸°
    picked = all_products[:COUNT] if all_products else []
    return picked

def build_html(products):
    seo_title = "ì˜¤ëŠ˜ì˜ ì¶”ì²œ íŠ¹ê°€ìƒí’ˆ 30ì„  | ì‡¼í•‘ëª° ë² ìŠ¤íŠ¸"
    seo_description = "ê°€ì „ì œí’ˆ, íŒ¨ì…˜, ìº í•‘ìš©í’ˆ, í—¬ìŠ¤, ì•„ë™ ì¥ë‚œê°ê¹Œì§€ ì˜¤ëŠ˜ì˜ ì¶”ì²œ ë² ìŠ¤íŠ¸ íŠ¹ê°€ìƒí’ˆ 30ê°œë¥¼ ëª¨ì•˜ìŠµë‹ˆë‹¤."
    seo_keywords = ",".join(SEARCH_KEYWORDS)
    og_image = (products[0].get("imageUrl") if products else "") or ""

    html = f"""<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>{seo_title}</title>
    <meta name="description" content="{seo_description}">
    <meta name="keywords" content="{seo_keywords}">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Open Graph -->
    <meta property="og:title" content="{seo_title}">
    <meta property="og:description" content="{seo_description}">
    <meta property="og:image" content="{og_image}">
    <meta property="og:url" content="{SITE_URL}">
    <link rel="canonical" href="{SITE_URL}">
    <meta name="twitter:card" content="summary_large_image">

    <style>
        body {{ font-family: Arial, sans-serif; max-width: 1200px; margin: auto; padding: 20px; }}
        .grid {{ display: grid; grid-template-columns: repeat(auto-fill, minmax(250px, 1fr)); gap: 20px; }}
        article {{ border: 1px solid #ddd; padding: 10px; border-radius: 10px; box-shadow: 2px 2px 8px rgba(0,0,0,0.1); }}
        article img {{ max-width: 100%; border-radius: 10px; }}
        .price {{ font-weight: bold; color: red; margin-top: 5px; }}
        .btn {{ display: inline-block; margin-top: 10px; padding: 8px 12px; background: #ff5722; color: #fff; text-decoration: none; border-radius: 5px; }}
        .btn:hover {{ background: #e64a19; }}
    </style>
</head>
<body>
    <h1>{seo_title}</h1>
    <p>â€» ì´ í¬ìŠ¤íŒ…ì€ ì¿ íŒ¡ íŒŒíŠ¸ë„ˆìŠ¤ í™œë™ì˜ ì¼í™˜ìœ¼ë¡œ, ì¼ì •ì•¡ì˜ ìˆ˜ìˆ˜ë£Œë¥¼ ì œê³µë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
    <div class="grid">
"""
    for p in products:
      name = (p.get("productName") or p.get("title") or "")[:60]
      desc = (p.get("productName") or p.get("title") or "")[:120]
      price = p.get("productPrice") or p.get("price") or ""
      img = p.get("imageUrl") or p.get("image") or ""
      link = p.get("productUrl") or p.get("link") or "#"

      html += f"""
      <article itemscope itemtype="https://schema.org/Product">
        <h2 itemprop="name">{name}...</h2>
        <img src="{img}" alt="{name}" itemprop="image">
        <p class="price"><span itemprop="price">{price}</span>ì›</p>
        <a class="btn" href="{link}" target="_blank" rel="nofollow noopener" itemprop="url">ğŸ‘‰ ë³´ëŸ¬ê°€ê¸°</a>
        <meta itemprop="brand" content="ì¿ íŒ¡">
        <meta itemprop="description" content="{desc}">
      </article>
      """
    html += """
    </div>
</body>
</html>
"""
    return html

def build_sitemap(products):
    # ì£¼ì˜: ì¿ íŒ¡ ì™¸ë¶€ URLì€ ë„¤ ë„ë©”ì¸ì´ ì•„ë‹ˆë¯€ë¡œ sitemapì—ëŠ” ë„£ì§€ ì•ŠëŠ” ê²Œ ì •ì„
    # ë„¤ ì‚¬ì´íŠ¸ ëŒ€í‘œ URLë§Œ ë„£ì.
    urls = [SITE_URL]
    xml = '<?xml version="1.0" encoding="UTF-8"?>\n'
    xml += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
    for url in urls:
        xml += f"  <url><loc>{url}</loc></url>\n"
    xml += "</urlset>"
    return xml

def build_robots():
    return f"""User-agent: *
Allow: /
Sitemap: {SITE_URL}sitemap.xml
"""

if __name__ == "__main__":
    # ë°ì´í„° ìˆ˜ì§‘
    products = fetch_random_products()

    # ìˆ˜ì§‘ ê²°ê³¼ ë¡œê·¸
    print(f"PRODUCT_COUNT={len(products)}")
    if products:
        try:
            print("FIRST_ITEM_TITLE=", str(products[0].get("productName", ""))[:80])
        except Exception as e:
            print("[WARN] first item preview failed:", e)

    # ë””ë²„ê·¸ ëª¨ë“œì—ì„œ ë¹„ì—ˆìœ¼ë©´ ë”ë¯¸ 1ê°œ ì£¼ì…(íŒŒì´í”„ë¼ì¸ ì ê²€)
    if not products and DEBUG:
        products = [{
            "productName": "ìƒ˜í”Œ ìƒí’ˆ(ì ê²€ìš©)",
            "price": "9,900",
            "imageUrl": "https://via.placeholder.com/600x400?text=Sample",
            "productUrl": "https://www.coupang.com/",
        }]
        print("[WARN] products empty â†’ injected 1 dummy item for pipeline test.")

    # íŒŒì¼ ìƒì„±
    html = build_html(products)
    sitemap = build_sitemap(products)
    robots = build_robots()

    # ì €ì¥
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(html)
    with open("sitemap.xml", "w", encoding="utf-8") as f:
        f.write(sitemap)
    with open("robots.txt", "w", encoding="utf-8") as f:
        f.write(robots)

    print("[OK] index.html/sitemap.xml/robots.txt written")
    print("== DEBUG END ==")
